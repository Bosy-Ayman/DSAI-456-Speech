{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PLu2ATO0F1mD",
        "rrBuFmiPobGa"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Section\n",
        "- Any given code is optional to help you; if you want to edit it, modify it, or implement your own, it's okay."
      ],
      "metadata": {
        "id": "NBDH3tgGEUzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "PLu2ATO0F1mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "a6rwiGaxF2Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Data"
      ],
      "metadata": {
        "id": "fNhXS5QmEXAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Wrtie a Python Code that reads four audio files (WAV format). For each file, load the audio using librosa and store the results in a dictionary where the **keys** are the **labels** and the values are tuples containing:\n",
        "\n",
        "  - The audio signal\n",
        "  - The sampling rate\n",
        "\n",
        "- Output Example:\n",
        "  - { \"e\": (signal_e, sr_e) }"
      ],
      "metadata": {
        "id": "oF0VBNv5HKT9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TezDgW8GDfnQ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "labels = [\"e\",\"j\",\"3\",\"7\"]\n",
        "\n",
        "audio_dict = {}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Isolation"
      ],
      "metadata": {
        "id": "8Gqfz_yLGhwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def isolator():\n",
        "  \"\"\"\n",
        "    Isolate individual strokes.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    strokes : list of torch.Tensor or numpy array or whatever datatype you use.\n",
        "        A list of 1D tensors or arrays, each containing an isolated audio segment (stroke).\n",
        "  \"\"\"\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "NMqYiSLDGjA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"Label\": [],\n",
        "    \"Signal\": []\n",
        "}\n",
        "\n",
        "for label, (signal, sample_rate) in audio_dict.items():\n",
        "\n",
        "    strokes = isolator()\n",
        "\n",
        "    # print(label, len(strokes)) or print(label, strokes.shape) # one of those two print lines should be work depend on your datatype return from isolation function.\n",
        "\n",
        "    for stroke in strokes:\n",
        "        data[\"Label\"].append(label)\n",
        "        data[\"Signal\"].append(stroke)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "id": "GIUa9dYDJZM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(signal, sample_rate, n_mfcc=13):\n",
        "    mfcc = librosa.feature.mfcc(y=np.asarray(signal), sr=sample_rate, n_mfcc=n_mfcc)\n",
        "    return np.hstack([mfcc.mean(axis=1), mfcc.std(axis=1)])"
      ],
      "metadata": {
        "id": "i-MYkjh_onNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    signal = row[\"Signal\"]\n",
        "    label = row[\"Label\"]\n",
        "    feat = extract_features(signal.squeeze(), sample_rate)\n",
        "    X.append(feat)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "print(\"X Shape is:\", X.shape)\n",
        "print(\"y Shape is:\", y.shape)"
      ],
      "metadata": {
        "id": "p6zULyQJokiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GMM"
      ],
      "metadata": {
        "id": "rrBuFmiPobGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_pdf(x, mean, cov):\n",
        "    d = len(x)\n",
        "    cov += np.eye(d) * 1e-6  # numerical stability\n",
        "    det = np.linalg.det(cov)\n",
        "    inv = np.linalg.inv(cov)\n",
        "    norm = 1.0 / np.sqrt((2 * np.pi) ** d * det)\n",
        "    diff = x - mean\n",
        "    return norm * np.exp(-0.5 * diff @ inv @ diff)"
      ],
      "metadata": {
        "id": "0haHWYjnoY1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You can ignore this function description and implement your own, but it should correctly implement train_gmm **from scratch.**"
      ],
      "metadata": {
        "id": "aHl4c3SKtqmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gmm(X, K, n_iters=2):\n",
        "    \"\"\"\n",
        "    Train a Gaussian Mixture Model (GMM) on the given dataset using the\n",
        "    Expectation-Maximization (EM) algorithm.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : np.ndarray\n",
        "        Input data matrix of shape (N, D), where N is the number of samples\n",
        "        and D is the dimensionality of each feature vector.\n",
        "    K : int\n",
        "        Number of Gaussian components in the mixture model.\n",
        "    n_iters : int, optional\n",
        "        Number of EM iterations to perform (default is 50).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    weights : np.ndarray\n",
        "        Array of mixture weights for each Gaussian component (length K).\n",
        "    means : np.ndarray\n",
        "        Array of mean vectors for each Gaussian component (shape K x D).\n",
        "    covs : list of np.ndarray\n",
        "        List containing the covariance matrices for each Gaussian component\n",
        "        (each of shape D x D).\n",
        "\n",
        "    Method\n",
        "    ------\n",
        "    1. Initialize:\n",
        "       - Select K random samples from X as the initial means.\n",
        "       - Initialize each component's covariance matrix using the sample covariance.\n",
        "       - Set mixture weights uniformly (1/K for each component).\n",
        "\n",
        "    2. Repeat EM steps for n_iters iterations:\n",
        "       a) E-step (Expectation):\n",
        "          - For each data point and each Gaussian component, compute the\n",
        "            responsibility (posterior probability) using the current means,\n",
        "            covariances, and mixture weights.\n",
        "          - Normalize the responsibilities across components for each data point.\n",
        "          - Compute Nk, the effective number of points assigned to each component.\n",
        "\n",
        "       b) M-step (Maximization):\n",
        "          - Update each Gaussian's mean using the weighted average of the data,\n",
        "            weighted by the responsibilities.\n",
        "          - Update each Gaussian's covariance matrix using the weighted outer\n",
        "            product of deviations from the mean.\n",
        "          - Update the mixture weights as Nk divided by the total number of samples.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - This implementation uses a full covariance matrix for each Gaussian.\n",
        "    - The function assumes a multivariate Gaussian PDF for computing responsibilities.\n",
        "    - The returned parameters can be used directly for likelihood computation\n",
        "      or for making predictions with new data.\n",
        "    \"\"\"\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "PjneaPwKpxgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gmms = {}\n",
        "K = 4  # number of Gaussian components\n",
        "\n",
        "for label in np.unique(y):\n",
        "    X_class = X[y == label]\n",
        "    gmms[label] = train_gmm(X_class, K)\n",
        "    print(\"Train is done for label:   \", label)"
      ],
      "metadata": {
        "id": "5L1BvFfsprZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion"
      ],
      "metadata": {
        "id": "C-m966HKqiAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explain your isolation logic"
      ],
      "metadata": {
        "id": "dy2F6mvGqjZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the main use of GMM models?"
      ],
      "metadata": {
        "id": "WQKDHsW1XxN8"
      }
    }
  ]
}