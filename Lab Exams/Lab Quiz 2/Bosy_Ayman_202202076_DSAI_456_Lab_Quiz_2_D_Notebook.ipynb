{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Question"
      ],
      "metadata": {
        "id": "Hw4Jpi4S4_JA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CTC Loss"
      ],
      "metadata": {
        "id": "hu9uKue79Ab7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "-p69dVJd5DRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ctc_loss(log_probs):\n",
        "    \"\"\"\n",
        "    Compute CTC loss based on the log-probability matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    final_prob =-np.log(log_probs)\n",
        "    loss = np.sum(final_prob)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "L_A5TfhD5LEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_probs = np.array([\n",
        "    [0.6, 0.2, 0.1, 0.1],\n",
        "    [0.1, 0.7, 0.1, 0.1],\n",
        "    [0.1, 0.1, 0.7, 0.1],\n",
        "    [0.1, 0.6, 0.1, 0.2],\n",
        "])\n",
        "\n",
        "loss = ctc_loss(log_probs)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "r3bV-UpD5LoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e51eb3-da85-4394-a38d-2733e2a8c592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.9797278902181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Greedy Decoding\n",
        "**You are NOT allowed to use np.argmax or any similar function**"
      ],
      "metadata": {
        "id": "n0Ag464N9C-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_ctc_decode(probs, idx2char):\n",
        "    \"\"\"\n",
        "    Greedy CTC decoding:\n",
        "      - probs: list of lists, shape (T, V)\n",
        "      - idx2char: dict mapping index -> character\n",
        "    \"\"\"\n",
        "    T,C = probs.shape\n",
        "    # print(T,C)\n",
        "    list_greedy = []\n",
        "\n",
        "    # 1) Argmax over classes at each timestep\n",
        "    for t in range(T):\n",
        "      idx = 0\n",
        "      max_val = probs[t][0]\n",
        "      for char in range(C):\n",
        "          val = probs[t][char]\n",
        "          if max_val< val:\n",
        "            max_val = val\n",
        "            idx = char\n",
        "      list_greedy.append(idx)\n",
        "      # print(list_greedy)\n",
        "    #2) Collapse repeats and remove blanks\n",
        "    final_list = []\n",
        "    char_list= []\n",
        "    prev = None\n",
        "\n",
        "    # 3) Map indices to characters\n",
        "    # 4) Join characters and return the predicted word\n",
        "\n",
        "    for char in (list_greedy):\n",
        "      if list_greedy[char]!=prev and list_greedy[char]!=0:\n",
        "        prev = list_greedy[char]\n",
        "        # print(prev)\n",
        "      final_list.append(prev)\n",
        "\n",
        "      char_list.append(idx2char[prev])\n",
        "    # 4) Join characters and return the predicted word\n",
        "    # idx2char[prev]\n",
        "    return char_list,final_list"
      ],
      "metadata": {
        "id": "753pe2bC9ET8"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Vocabulary:\n",
        "    # 0 = blank '_'\n",
        "    # 1 = 'A'\n",
        "    # 2 = 'B'\n",
        "    # 3 = 'C'\n",
        "    idx2char = {\n",
        "        0: \"_\",\n",
        "        1: \"A\",\n",
        "        2: \"B\",\n",
        "        3: \"C\"\n",
        "    }\n",
        "\n",
        "    # probs[t][v] = probability of symbol v at time t\n",
        "    probs =np.array( [\n",
        "        [0.1, 0.6, 0.2, 0.1],  # t0 -> 'A'\n",
        "        [0.1, 0.7, 0.1, 0.1],  # t1 -> 'A'\n",
        "        [0.5, 0.3, 0.1, 0.1],  # t2 -> blank\n",
        "        [0.1, 0.1, 0.7, 0.1],  # t3 -> 'B'\n",
        "        [0.1, 0.1, 0.7, 0.1],  # t4 -> 'B'\n",
        "        [0.2, 0.1, 0.1, 0.6],  # t5 -> 'C'\n",
        "    ])\n",
        "\n",
        "    decoded = greedy_ctc_decode(probs, idx2char)\n",
        "    print(\"Decoded word:\", decoded)"
      ],
      "metadata": {
        "id": "zvn9gCp49NnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b842030-0e47-45f2-f6a3-78cd12e4b0c9"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded word: (['A', 'A', 'A', 'A', 'A', 'B'], [1, 1, 1, 1, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discusison Quesiton"
      ],
      "metadata": {
        "id": "h1kMq0Kz5ADC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.because we only need to calculate the sum of the negative log over the probabilities matrix"
      ],
      "metadata": {
        "id": "h4o1216V9xuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "_FX9sg3-jgeM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. We calculate all possible probabilities over for the sentence (phonemes) so that we could find the best alignment per the audio for each word.\n",
        "We need to add a blank to cover 3 cases\n",
        "- char->blank  = char (stay)\n",
        "- char->char = char (skip)\n",
        "- char1->char2 = char1 - char2 (move)\n",
        "\n",
        "we need a decoder beside adding blanks\n",
        "*Ex:*\n",
        "- Greedy -->calculate max prob over each timestep\n",
        "- Beam-->calculate max prob per k of sequence\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k5attJwp9y2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "WQ7fCRjtjfME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Beam has a better stategy than Greedy because it calculates the probability per k sequence (ex: k = 3) which are the best sequences so far per the timestep\n",
        "\n",
        "- while the algorithm is working, if the one of the sequence return a bad max prob , the algo search for another best sequence (alternative).\n",
        "- this ensures that we care about the accumlative sequence per all timestep (beam) rather that taking the max per each timestep (greedy)\n",
        "\n"
      ],
      "metadata": {
        "id": "zyWSE-GshHAz"
      }
    }
  ]
}