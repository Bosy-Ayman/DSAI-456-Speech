{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMCfMqlr9jWFea4r4V/tG15",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bosy-Ayman/DSAI-456-Speech/blob/main/assignment-solutions/assignment%204/Assignment4_Speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GMM for Speaker Identification – Implementation Assignment**\n",
        "\n",
        "##  Objectives\n",
        "The goal of this assignment is to:\n",
        "- Implement the **Expectation-Maximization (EM) Algorithm**\n",
        "- Build **Gaussian Mixture Models (GMMs)** for speaker recognition\n",
        "- Gain skills in iterative algorithm development and probabilistic modeling\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset\n",
        "We will use the **VCTK Corpus** from Kaggle:\n",
        "- Contains speech recordings from **110 speakers**\n",
        "- Each speaker reads about **400 English sentences**\n",
        "- Single-sentence samples → suitable for classification where we train **one GMM per speaker**\n",
        "https://www.kaggle.com/datasets/pratt3000/vctk-corpus\n",
        "---\n",
        "\n",
        "##  Task Requirements\n",
        "\n",
        "###  Download Dataset\n",
        "- Download the **VCTK Corpus** from Kaggle\n",
        "- Organize recordings by speaker (each class = one speaker)\n",
        "\n",
        "---\n",
        "\n",
        "###  Feature Extraction\n",
        "Extract useful audio features, such as:\n",
        "- **MFCCs**\n",
        "- **Mel Filter Banks**\n",
        "\n",
        "> MFCCs are recommended for speaker recognition\n",
        "\n",
        "---\n",
        "\n",
        "###   Implement EM Algorithm\n",
        "You **must implement EM yourself**\n",
        "( Not allowed: sklearn GaussianMixture or other libraries)\n",
        "\n",
        "Follow **slide 22 in Lecture 4**, including:\n",
        "- Initialize GMM parameters:  \n",
        "  - Mixing weights (πₖ)\n",
        "  - Means (μₖ)\n",
        "  - Covariance matrices (Σₖ)\n",
        "- Iteratively update using:\n",
        "  - **E-Step** → compute γ(zₙₖ)\n",
        "  - **M-Step** → update parameters based on γ values\n",
        "- Stop when convergence criteria is reached\n",
        "\n",
        "---\n",
        "\n",
        "###  Train One GMM per Speaker\n",
        "- Each speaker has **multiple utterances** → combine extracted features\n",
        "- Train a **separate GMM** for each speaker\n",
        "- Store estimated parameters for testing\n",
        "\n",
        "---\n",
        "\n",
        "###   Speaker Prediction (Evaluation)\n",
        "For each test audio sample:\n",
        "1. Extract MFCC features\n",
        "2. Compute the **log likelihood** of the sample under each speaker’s GMM\n",
        "3. **Classification** → choose the speaker with the **highest likelihood**\n",
        "\n",
        "---\n",
        "\n",
        "##  Final Deliverables\n",
        "- Code for:\n",
        "  - Feature extraction\n",
        "  - EM for GMM training\n",
        "  - Speaker identification testing\n",
        "- Accuracy evaluation\n",
        "- Short explanation/report on results\n",
        "\n",
        "---\n",
        "\n",
        "##  Bonus (Optional)\n",
        "- Experiment with different number of mixtures (e.g., K = 8, 16, 32)\n",
        "- Compare MFCCs vs. Mel filter bank performance\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "-MYp72leKu8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.cluster import KMeans\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import kagglehub\n"
      ],
      "metadata": {
        "id": "NxlBbT7tIuSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HJ6MDmLIAKW",
        "outputId": "1380c291-2a08-4987-b5d1-b469899d44f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'vctk-corpus' dataset.\n",
            "Path to dataset files: /kaggle/input/vctk-corpus\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"pratt3000/vctk-corpus\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KAGGLE_DOWNLOAD_PATH = \"/kaggle/input/vctk-corpus\"\n",
        "DATASET_PATH = os.path.join(KAGGLE_DOWNLOAD_PATH, \"VCTK-Corpus\", \"VCTK-Corpus\", \"wav48\")"
      ],
      "metadata": {
        "id": "OK9KYtUaTWLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_SPEAKERS = 10\n",
        "N_MFCC = 13\n",
        "N_MIXTURES = 8  # Number of GMM components (K)\n",
        "MAX_ITER = 20\n",
        "TOLERANCE = 1e-4"
      ],
      "metadata": {
        "id": "XY6EI8xCQwcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Steps**\n",
        "*Audio → MFCCs → Train GMM per Speaker → Log-Likelihood Test → Prediction*"
      ],
      "metadata": {
        "id": "bddLsZA_1BoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-trxqMZJ3oPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GMM Log-Likelihood"
      ],
      "metadata": {
        "id": "XA8Xy3RLxGWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multivariate_gaussian_log_pdf(X, mean, cov):\n",
        "\n",
        "    D = X.shape[1]\n",
        "    diff = X - mean\n",
        "    try:\n",
        "        sign, logdet = np.linalg.slogdet(cov)\n",
        "    except np.linalg.LinAlgError:\n",
        "        cov_reg = cov + np.eye(D) * 1e-6\n",
        "        sign, logdet = np.linalg.slogdet(cov_reg)\n",
        "\n",
        "    if sign <= 0:\n",
        "        return -np.inf * np.ones(X.shape[0])\n",
        "\n",
        "    try:\n",
        "        inv_cov = np.linalg.inv(cov)\n",
        "    except np.linalg.LinAlgError:\n",
        "        inv_cov = np.linalg.inv(cov + np.eye(D) * 1e-6)\n",
        "\n",
        "    mahalanobis = -0.5 * np.sum(diff @ inv_cov * diff, axis=1)\n",
        "\n",
        "    log_pdf = -0.5 * D * np.log(2 * np.pi) - 0.5 * logdet + mahalanobis\n",
        "    return log_pdf\n"
      ],
      "metadata": {
        "id": "aGur9bsgRjDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_gmm_log_likelihood(X, weights, means, covs):\n",
        "\n",
        "    K = len(weights)\n",
        "    N = X.shape[0]\n",
        "    log_probs = np.zeros((N, K))\n",
        "\n",
        "    for k in range(K):\n",
        "        log_probs[:, k] = np.log(weights[k] + 1e-10) + multivariate_gaussian_log_pdf(X, means[k], covs[k])\n",
        "\n",
        "    max_log_probs = np.max(log_probs, axis=1, keepdims=True)\n",
        "    log_sum_exp = max_log_probs + np.log(np.sum(np.exp(log_probs - max_log_probs), axis=1, keepdims=True))\n",
        "\n",
        "    total_log_likelihood = np.sum(log_sum_exp)\n",
        "    return total_log_likelihood"
      ],
      "metadata": {
        "id": "MhscZJD6R16Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction (MFCCs)\n"
      ],
      "metadata": {
        "id": "EBllht09xhhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(audio_path, n_mfcc=N_MFCC):\n",
        "        y, sr = librosa.load(audio_path, sr=None)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        mfccs = mfccs.T\n",
        "        return mfccs\n"
      ],
      "metadata": {
        "id": "W9EfN3M2R7WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[2] Collect Speaker Data"
      ],
      "metadata": {
        "id": "aTJoUdoEyBCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Collects all MFCCs for the specified number of speakers.\n",
        "\n",
        "**Returns:** {speaker_id: combined_mfcc_data}\n"
      ],
      "metadata": {
        "id": "iBg8lQNPwPCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def collect_speaker_data(dataset_path, n_speakers):\n",
        "\n",
        "    speaker_data = {}\n",
        "    speaker_dirs = sorted([d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))])\n",
        "\n",
        "    print(f\"Collecting data for {min(n_speakers, len(speaker_dirs))} speakers...\")\n",
        "\n",
        "    for speaker_id in tqdm(speaker_dirs[:n_speakers], desc=\"Collecting features\"):\n",
        "        speaker_path = os.path.join(dataset_path, speaker_id)\n",
        "        all_mfccs = []\n",
        "\n",
        "        for filename in os.listdir(speaker_path):\n",
        "            if filename.endswith(\".wav\"):\n",
        "                audio_path = os.path.join(speaker_path, filename)\n",
        "                mfccs = extract_features(audio_path, n_mfcc=N_MFCC)\n",
        "                if mfccs is not None and mfccs.size > 0:\n",
        "                    all_mfccs.append(mfccs)\n",
        "\n",
        "        if all_mfccs:\n",
        "            speaker_data[speaker_id] = np.vstack(all_mfccs)\n",
        "        else:\n",
        "            print(f\"Warning: No valid data found for speaker {speaker_id}\")\n",
        "\n",
        "    return speaker_data"
      ],
      "metadata": {
        "id": "Aqsv8lDER9-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization Using K-Means"
      ],
      "metadata": {
        "id": "uaueGcn9yPLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializes GMM parameters using KMeans clustering.\n",
        "X: (N_samples, N_features)\n",
        "K: Number of mixtures\n"
      ],
      "metadata": {
        "id": "MugQuBVC_MPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_gmm_parameters(X, K):\n",
        "\n",
        "    N, D = X.shape\n",
        "\n",
        "    # 1. Initialize Means (mu_k)\n",
        "    kmeans = KMeans(n_clusters=K, random_state=42, n_init=10, max_iter=100).fit(X)\n",
        "    initial_means = kmeans.cluster_centers_\n",
        "\n",
        "    # 2. Initialize Covariances\n",
        "    global_cov = np.cov(X, rowvar=False)\n",
        "    initial_covs = np.array([global_cov] * K)\n",
        "\n",
        "    # 3. Initialize Weights (pi_k)\n",
        "    counts = np.bincount(kmeans.labels_, minlength=K)\n",
        "    initial_weights = counts / N\n",
        "\n",
        "    initial_weights = np.maximum(initial_weights, 1e-10)\n",
        "    initial_weights /= np.sum(initial_weights)\n",
        "\n",
        "    return initial_weights, initial_means, initial_covs"
      ],
      "metadata": {
        "id": "38Uq_FUmSA4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EM Algorithm"
      ],
      "metadata": {
        "id": "8BkSSQrjyTDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **E-Step (Expectation):** We guess which Gaussian each MFCC frame belongs to.\n",
        "\n",
        "= \"Probability that point i belongs to Gaussian k\"\n",
        "\n",
        "*  **M-Step (Maximization):**\n",
        "\n",
        "  We update the Gaussian parameters:\n",
        "  * Update means → average MFCCs assigned\n",
        "  *  Update covariances → variation\n",
        "  * Update weights → how many belong to each Gaussian\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1SSMqsh72FhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def em_gmm(X, K, max_iter=MAX_ITER, tolerance=TOLERANCE):\n",
        "\n",
        "    N, D = X.shape\n",
        "\n",
        "    weights, means, covs = initialize_gmm_parameters(X, K)\n",
        "    log_likelihood_history = []\n",
        "\n",
        "    #-------------- E-STEP ---------------\n",
        "    for i in tqdm(range(max_iter)):\n",
        "        log_probs = np.zeros((N, K))\n",
        "        for k in range(K):\n",
        "\n",
        "            log_probs[:, k] = np.log(weights[k]) + multivariate_gaussian_log_pdf(X, means[k], covs[k])\n",
        "\n",
        "        max_log_probs = np.max(log_probs, axis=1, keepdims=True)\n",
        "        log_denominator = max_log_probs + np.log(np.sum(np.exp(log_probs - max_log_probs), axis=1, keepdims=True))\n",
        "        log_gamma = log_probs - log_denominator\n",
        "        gamma = np.exp(log_gamma)\n",
        "\n",
        "        # ---------------- M-STEP -------------\n",
        "        N_k = np.sum(gamma, axis=0)\n",
        "\n",
        "        #1. Update Weights (pi_k)\n",
        "        new_weights = N_k / N\n",
        "\n",
        "        #2. Update Covariances (Sigma_k)\n",
        "        new_means = (gamma.T @ X) / N_k[:, np.newaxis] # (K, D)\n",
        "\n",
        "        #2. Update Means (mu_k)\n",
        "        new_covs = np.zeros((K, D, D))\n",
        "        for k in range(K):\n",
        "            diff = X - new_means[k]\n",
        "            new_covs[k] = (diff.T * gamma[:, k]) @ diff / N_k[k]\n",
        "            new_covs[k] += np.eye(D) * 1e-6\n",
        "\n",
        "        weights, means, covs = new_weights, new_means, new_covs\n",
        "        current_log_likelihood = np.sum(log_denominator)\n",
        "        log_likelihood_history.append(current_log_likelihood)\n",
        "\n",
        "        if i > 0:\n",
        "            change = current_log_likelihood - log_likelihood_history[-2]\n",
        "            if abs(change) < tolerance:\n",
        "                print(f\"EM converged at iteration {i} (Change: {change:.6f}).\")\n",
        "                break\n",
        "\n",
        "    return weights, means, covs, log_likelihood_history"
      ],
      "metadata": {
        "id": "_zl8m1qMRn4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trains a separate GMM for each speaker.\n",
        "\n",
        "Returns: {speaker_id: (weights, means, covs)}\n"
      ],
      "metadata": {
        "id": "_nuoo1P2-Uh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gmm_models(speaker_data, K=N_MIXTURES):\n",
        "    gmm_models = {}\n",
        "    print(f\"\\nTraining GMMs (K={K}) for {len(speaker_data)} speakers...\")\n",
        "\n",
        "    for speaker_id, X in speaker_data.items():\n",
        "        print(f\"Training GMM for speaker {speaker_id} ({X.shape[0]} frames)...\")\n",
        "        if X.shape[0] < K:\n",
        "            print(f\"Skipping speaker {speaker_id}: not enough data frames.\")\n",
        "            continue\n",
        "\n",
        "        weights, means, covs, _ = em_gmm(X, K)\n",
        "        gmm_models[speaker_id] = (weights, means, covs)\n",
        "\n",
        "    return gmm_models"
      ],
      "metadata": {
        "id": "Q6qKRoFARri_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speaker Prediction (Evaluation)\n",
        "\n",
        "1. Compute log likelihood under each speaker's GMM.\n",
        "2. Choose the speaker with the maximum log likelihood."
      ],
      "metadata": {
        "id": "vL_nLuYaSR_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_speaker(audio_features, trained_gmms):\n",
        "    best_log_likelihood = -np.inf\n",
        "    predicted_speaker = None\n",
        "\n",
        "    for speaker_id, (weights, means, covs) in trained_gmms.items():\n",
        "        log_likelihood = compute_gmm_log_likelihood(audio_features, weights, means, covs)\n",
        "\n",
        "        if log_likelihood > best_log_likelihood:\n",
        "            best_log_likelihood = log_likelihood\n",
        "            predicted_speaker = speaker_id\n",
        "\n",
        "    return predicted_speaker\n"
      ],
      "metadata": {
        "id": "P9AkkK-4SQzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "7DE23VjjzJ_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NimTN3TwzOLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_performance(test_data, trained_gmms):\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    speaker_ids = list(test_data.keys())\n",
        "\n",
        "    print(\"\\n--- Evaluation Phase ---\")\n",
        "    for true_speaker_id in tqdm(speaker_ids, desc=\"Evaluating Speakers\"):\n",
        "\n",
        "        test_features = test_data.get(true_speaker_id)\n",
        "\n",
        "        if test_features is None or test_features.size == 0:\n",
        "            continue\n",
        "\n",
        "        # 1. Predict speaker for the test features\n",
        "        predicted_speaker_id = predict_speaker(test_features, trained_gmms)\n",
        "\n",
        "        # 2. Classification\n",
        "        if predicted_speaker_id == true_speaker_id:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        total_samples += 1\n",
        "\n",
        "    accuracy = (correct_predictions / total_samples) if total_samples > 0 else 0.0\n",
        "\n",
        "    return accuracy, total_samples\n"
      ],
      "metadata": {
        "id": "vUiO_QQkScEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "LXPZfDFTzxhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "speaker_mfcc_data = collect_speaker_data(DATASET_PATH, N_SPEAKERS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkjMTjrnv2hA",
        "outputId": "fc8148dd-9b97-404b-b460-dfc5d29896ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting data for 10 speakers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Collecting features: 100%|██████████| 10/10 [01:48<00:00, 10.87s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = {}\n",
        "test_data = {}\n",
        "\n",
        "for speaker_id, all_frames in speaker_mfcc_data.items():\n",
        "        split_idx = int(0.8 * all_frames.shape[0])\n",
        "        train_data[speaker_id] = all_frames[:split_idx]\n",
        "        test_data[speaker_id] = all_frames[split_idx:]"
      ],
      "metadata": {
        "id": "FedgiDPu0BFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_gmms = train_gmm_models(train_data, K=N_MIXTURES)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta7wWeuu0WdB",
        "outputId": "3aca9b6e-924c-48d2-b9c9-355a02c87531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training GMMs (K=8) for 10 speakers...\n",
            "Training GMM for speaker p225 (74240 frames)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:08<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMM for speaker p226 (117072 frames)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMM for speaker p227 (108445 frames)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMM for speaker p228 (113811 frames)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMM for speaker p229 (91193 frames)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMM for speaker p230 (115446 frames)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMM for speaker p231 (90292 frames)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMM for speaker p232 (94600 frames)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMM for speaker p233 (101736 frames)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMM for speaker p234 (91596 frames)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, total_speakers_tested = evaluate_performance(test_data, trained_gmms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1cUG-I80aGU",
        "outputId": "54889a90-39dd-48c1-910f-4a9c2c0cbc32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation Phase ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Speakers: 100%|██████████| 10/10 [00:04<00:00,  2.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total Speakers Used: {N_SPEAKERS}\")\n",
        "print(f\"Number of MFCCs (D): {N_MFCC}\")\n",
        "print(f\"Number of Mixtures (K): {N_MIXTURES}\")\n",
        "print(f\"EM Max Iterations: {MAX_ITER}\")\n",
        "print(f\"Total Speakers Tested: {total_speakers_tested}\")\n",
        "print(f\"Correctly Identified Speakers: {int(accuracy * total_speakers_tested)}\")\n",
        "print(f\"Speaker Identification Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PrgPuYkUBlo",
        "outputId": "4082f64c-4c23-4691-fcda-85a02d513810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Speakers Used: 10\n",
            "Number of MFCCs (D): 13\n",
            "Number of Mixtures (K): 8\n",
            "EM Max Iterations: 20\n",
            "Total Speakers Tested: 10\n",
            "Correctly Identified Speakers: 10\n",
            "Speaker Identification Accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ]
}